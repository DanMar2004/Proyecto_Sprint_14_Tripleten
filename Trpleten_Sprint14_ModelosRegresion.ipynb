{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Sprint 14\n",
    "\n",
    "Para este proyecto trabajaremos un caso practico de la empresa Rusty Bargain que se dedica a la venta de autos usados, que esta desarrollando una aplicacion para averiguar rapidamente el valor en el mercado de un auto. \n",
    "Tenemos acceso a una base de datos que tiene informacion de 356,000 autos en donde podemos encotrar la marca, el precio, tipo de gasolina que usa entre otras caracteristicas.\n",
    "\n",
    "Objetivo: Revisar entre los diferentes Modelos de regresion como Regresion Lineal, Bosque aleatorio y otros cual tiene mejor prediccion usando la metrica de Raiz del Error cuadratico Medio y tambien considerando los tiempos de entrenamiento y prediccion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacion de librerias \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math \n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis Exploratorio de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   DateCrawled        354369 non-null  object\n",
      " 1   Price              354369 non-null  int64 \n",
      " 2   VehicleType        316879 non-null  object\n",
      " 3   RegistrationYear   354369 non-null  int64 \n",
      " 4   Gearbox            334536 non-null  object\n",
      " 5   Power              354369 non-null  int64 \n",
      " 6   Model              334664 non-null  object\n",
      " 7   Mileage            354369 non-null  int64 \n",
      " 8   RegistrationMonth  354369 non-null  int64 \n",
      " 9   FuelType           321474 non-null  object\n",
      " 10  Brand              354369 non-null  object\n",
      " 11  NotRepaired        283215 non-null  object\n",
      " 12  DateCreated        354369 non-null  object\n",
      " 13  NumberOfPictures   354369 non-null  int64 \n",
      " 14  PostalCode         354369 non-null  int64 \n",
      " 15  LastSeen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Vista general del dataset\n",
    "df = pd.read_csv('data/car_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisar valores nulos en el dataset\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porcentaje de valores nulos por columna\n",
    "print(\"\\nPorcentaje de valores nulos por columna:\")\n",
    "print((df.isnull().sum() / len(df)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que las columnas que tiene valores faltantes son 'VehicleType', 'Gearbox', 'Model', 'FuelType' y 'Notrepaired'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar tipos de datos de cada columna\n",
    "print(\"Tipos de datos por columna:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Revisar algunas filas para entender los datos\n",
    "print(\"\\nPrimeras 5 filas del dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que tenemos caracteristicas categoricas y numericas por lo que despues tendremos que codificarlas o escalarlas para que se puedan entrenar mejor nuestros modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentamos usar K-NearestNeighbor para la imputacion de datos ya que analizando podemos saber que un tipo de vehiculo como las SUV que regularmente tiene una caja automatica, con esta idea este metodo nos podra ayudar a hacer una suposicion mas acercada a la realidad y el modelo pueda entrenarse mejor lamentablemente por la magnitud del dataset toma demasiados recursos hacer esta imputacion por lo que optaremos por rellenar con unknow los datos categoricos faltantes, esta parte creemos que es beneficiosa ya que en un escenario de practica real puede que igual falten datos y aun asi queremos saber una aproximacion del precio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar valores nulos en columnas categóricas con 'unknown'\n",
    "categorical_columns = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'NotRepaired']\n",
    "for col in categorical_columns:\n",
    "    df[col].fillna('unknown', inplace=True)\n",
    "\n",
    "# Verificar que ya no hay nulos\n",
    "print(\"Valores nulos tras rellenar con 'unknown':\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleccion de Caracteristicas Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas no relevantes para la predicción\n",
    "columns_to_drop = ['DateCrawled', 'DateCreated', 'LastSeen', 'NumberOfPictures', 'PostalCode']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Mostrar columnas restantes\n",
    "print(\"Columnas seleccionadas:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Escalamiento y codificacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mantener el dataset original con categorías en texto para CatBoost\n",
    "df_catboost = df.copy()\n",
    "print(\"Dataset para CatBoost (categorías sin codificar):\")\n",
    "print(df_catboost.head())\n",
    "\n",
    "# Crear una versión codificada para otros modelos\n",
    "df_encoded = df.copy()\n",
    "categorical_columns = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'NotRepaired', 'Brand']\n",
    "\n",
    "# Aplicar LabelEncoder a las columnas categóricas\n",
    "le = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "\n",
    "# Mostrar primeras filas del dataset codificado\n",
    "print(\"\\nDataset codificado para otros modelos (Regresión Lineal, XGBoost, etc.):\")\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de modelos de regresion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las caracteristicas y objetivo en el df_encoded\n",
    "X_encoded = df_encoded.drop(columns=['Price'])\n",
    "y = df_encoded['Price']\n",
    "\n",
    "# Definir las caracteristicas y objetivo en df_catboost\n",
    "X_catboost = df_catboost.drop(columns=['Price'])\n",
    "\n",
    "# Lista para almacenar tiempos y métricas\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjunto de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "# Usamos una sola división para mantener los índices consistentes\n",
    "train_idx, test_idx = train_test_split(range(len(y)), test_size=0.2, random_state=42)\n",
    "\n",
    "# Aplicar los índices a ambos conjuntos de características y objetivos \n",
    "X_train_enc, X_test_enc = X_encoded.iloc[train_idx], X_encoded.iloc[test_idx]\n",
    "X_train_cat, X_test_cat = X_catboost.iloc[train_idx], X_catboost.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar regresión lineal\n",
    "start_time_train = time.time()\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_enc, y_train)\n",
    "training_time_lr = time.time() - start_time_train\n",
    "\n",
    "# Predecir y calcular tiempo de predicción\n",
    "start_time_pred = time.time()\n",
    "y_pred_lr = lr_model.predict(X_test_enc)\n",
    "prediction_time_lr = time.time() - start_time_pred\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "# Guardar resultados\n",
    "results.append({\n",
    "    'Model': 'Linear Regression',\n",
    "    'Training Time': training_time_lr,\n",
    "    'Prediction Time': prediction_time_lr,\n",
    "    'RMSE': rmse_lr\n",
    "})\n",
    "print(f\"Regresión Lineal - Tiempo de entrenamiento: {training_time_lr:.2f}s, Tiempo de predicción: {prediction_time_lr:.2f}s, RECM: {rmse_lr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraciones de hiperparámetros para Bosque aleatorio\n",
    "rf_configs = [\n",
    "    {'n_estimators': 50, 'max_depth': 10, 'random_state': 42},\n",
    "    {'n_estimators': 100, 'max_depth': 20, 'random_state': 42},\n",
    "    {'n_estimators': 200, 'max_depth': 30, 'random_state': 42}\n",
    "]\n",
    "\n",
    "# Entrenar y evaluar cada configuración# Entrenar y evaluar cada configuración\n",
    "for i, config in enumerate(rf_configs, 1):\n",
    "    start_time_train = time.time()\n",
    "    rf_model = RandomForestRegressor(**config)\n",
    "    rf_model.fit(X_train_enc, y_train)\n",
    "    training_time_rf = time.time() - start_time_train\n",
    "    \n",
    "    start_time_pred = time.time()\n",
    "    y_pred_rf = rf_model.predict(X_test_enc)\n",
    "    prediction_time_rf = time.time() - start_time_pred\n",
    "    rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "    \n",
    "    results.append({\n",
    "        'Model': f'Random Forest {i}',\n",
    "        'Training Time': training_time_rf,\n",
    "        'Prediction Time': prediction_time_rf,\n",
    "        'RMSE': rmse_rf\n",
    "    })\n",
    "    print(f\"Bosque Aleatorio {i} - Tiempo de entrenamiento: {training_time_rf:.2f}s, Tiempo de predicción: {prediction_time_rf:.2f}s, RECM: {rmse_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraciones de hiperparámetros para LightGBM\n",
    "lgb_configs = [\n",
    "    {'n_estimators': 50, 'max_depth': 4, 'learning_rate': 0.1, 'random_state': 42},\n",
    "    {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.05, 'random_state': 42},\n",
    "    {'n_estimators': 150, 'max_depth': 8, 'learning_rate': 0.01, 'random_state': 42}\n",
    "]\n",
    "\n",
    "# Entrenar y evaluar cada configuración\n",
    "for i, config in enumerate(lgb_configs, 1):\n",
    "    start_time_train = time.time()\n",
    "    lgb_model = lgb.LGBMRegressor(**config)\n",
    "    lgb_model.fit(X_train_enc, y_train)\n",
    "    training_time_lgb = time.time() - start_time_train\n",
    "    \n",
    "    start_time_pred = time.time()\n",
    "    y_pred_lgb = lgb_model.predict(X_test_enc)\n",
    "    prediction_time_lgb = time.time() - start_time_pred\n",
    "    rmse_lgb = np.sqrt(mean_squared_error(y_test, y_pred_lgb))\n",
    "    \n",
    "    results.append({\n",
    "        'Model': f'LightGBM {i}',\n",
    "        'Training Time': training_time_lgb,\n",
    "        'Prediction Time': prediction_time_lgb,\n",
    "        'RMSE': rmse_lgb\n",
    "    })\n",
    "    print(f\"LightGBM {i} - Tiempo de entrenamiento: {training_time_lgb:.2f}s, Tiempo de predicción: {prediction_time_lgb:.2f}s, RECM: {rmse_lgb:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un directorio temporal si no existe\n",
    "temp_dir = 'C:/Users/Usuario/temp_catboost'  # Cambia a '/tmp' en plataformas Unix si es necesario\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "\n",
    "# Identificar columnas categóricas para CatBoost\n",
    "cat_features = ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'NotRepaired', 'Brand']\n",
    "\n",
    "# Configuraciones de hiperparámetros con directorio explícito\n",
    "cat_configs = [\n",
    "    {'iterations': 100, 'depth': 6, 'learning_rate': 0.1, 'random_seed': 42, 'logging_level': 'Silent', 'save_snapshot': False, 'train_dir': temp_dir},\n",
    "    {'iterations': 200, 'depth': 8, 'learning_rate': 0.05, 'random_seed': 42, 'logging_level': 'Silent', 'save_snapshot': False, 'train_dir': temp_dir},\n",
    "    {'iterations': 300, 'depth': 10, 'learning_rate': 0.01, 'random_seed': 42, 'logging_level': 'Silent', 'save_snapshot': False, 'train_dir': temp_dir}\n",
    "]\n",
    "\n",
    "# Entrenar y evaluar cada configuración\n",
    "for i, config in enumerate(cat_configs, 1):\n",
    "    start_time_train = time.time()\n",
    "    cat_model = CatBoostRegressor(**config)\n",
    "    cat_model.fit(X_train_cat, y_train, cat_features=cat_features)\n",
    "    training_time_cat = time.time() - start_time_train\n",
    "    \n",
    "    start_time_pred = time.time()\n",
    "    y_pred_cat = cat_model.predict(X_test_cat)\n",
    "    prediction_time_cat = time.time() - start_time_pred\n",
    "    rmse_cat = np.sqrt(mean_squared_error(y_test, y_pred_cat))\n",
    "    \n",
    "    results.append({\n",
    "        'Model': f'CatBoost {i}',\n",
    "        'Training Time': training_time_cat,\n",
    "        'Prediction Time': prediction_time_cat,\n",
    "        'RMSE': rmse_cat\n",
    "    })\n",
    "    print(f\"CatBoost {i} - Tiempo de entrenamiento: {training_time_cat:.2f}s, Tiempo de predicción: {prediction_time_cat:.2f}s, RECM: {rmse_cat:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraciones de hiperparámetros para XGBoost\n",
    "xgb_configs = [\n",
    "    {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1, 'random_state': 42},\n",
    "    {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.05, 'random_state': 42},\n",
    "    {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.01, 'random_state': 42}\n",
    "]\n",
    "\n",
    "# Entrenar y evaluar cada configuración\n",
    "for i, config in enumerate(xgb_configs, 1):\n",
    "    start_time_train = time.time()\n",
    "    xgb_model = xgb.XGBRegressor(**config)\n",
    "    xgb_model.fit(X_train_enc, y_train)\n",
    "    training_time_xgb = time.time() - start_time_train\n",
    "    \n",
    "    start_time_pred = time.time()\n",
    "    y_pred_xgb = xgb_model.predict(X_test_enc)\n",
    "    prediction_time_xgb = time.time() - start_time_pred\n",
    "    rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "    \n",
    "    results.append({\n",
    "        'Model': f'XGBoost {i}',\n",
    "        'Training Time': training_time_xgb,\n",
    "        'Prediction Time': prediction_time_xgb,\n",
    "        'RMSE': rmse_xgb\n",
    "    })\n",
    "    print(f\"XGBoost {i} - Tiempo de entrenamiento: {training_time_xgb:.2f}s, Tiempo de predicción: {prediction_time_xgb:.2f}s, RECM: {rmse_xgb:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis del modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir results a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Ordenar por RECM (calidad de predicción) de menor a mayor\n",
    "results_df = results_df.sort_values(by='RMSE')\n",
    "\n",
    "# Mostrar tabla\n",
    "print(\"Tabla comparativa de modelos:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por Training Time de menor a mayor\n",
    "results_df = results_df.sort_values(by='Training Time')\n",
    "\n",
    "# Mostrar tabla\n",
    "print(\"Tabla comparativa de modelos:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por RPrediction Time de menor a mayor\n",
    "results_df = results_df.sort_values(by='Prediction Time')\n",
    "\n",
    "# Mostrar tabla\n",
    "print(\"Tabla comparativa de modelos:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones \n",
    "\n",
    "De acuerdo al objetivo donde es escoger un modelo que tenga buena prediccion, rapida velocidad de entrenamiento y rapida velocidad de predicion podemos optar por un modelo XGBoost donde la metrica RECM tiene de las mas bajas diferencia entre lo predicho y lo real y donde el tiempo entrenamiento y prediccion no son tan altos como en un Random Forest, la desicion de tomar un modelo y otro dependera de los recursos con los que contamos como equipo y tiempo asi como el objetivo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
